<p align="center">
    <h1 align="center">
      <picture>
        <source media="(prefers-color-scheme: dark)" srcset="https://github.com/semaphore-protocol/website/blob/main/static/img/semaphore-icon-dark.svg">
        <source media="(prefers-color-scheme: light)" srcset="https://github.com/semaphore-protocol/website/blob/main/static/img/semaphore-icon.svg">
        <img width="40" alt="Semaphore icon." src="https://github.com/semaphore-protocol/website/blob/main/static/img/semaphore-icon.svg">
      </picture>
      IEF: public goods anonymous peer impact measurement review
    </h1>
</p>

<div align="center">
    <h4>
        <a href="/CONTRIBUTING.md">
            üë• Framework
        </a>
        <span>&nbsp;&nbsp;|&nbsp;&nbsp;</span>
        <a href="/CODE_OF_CONDUCT.md">
            ü§ù Mechanism
        </a>
        <span>&nbsp;&nbsp;|&nbsp;&nbsp;</span>
        <a href="https://github.com/semaphore-protocol/semaphore/contribute">
            üîé Research
        </a>
        <span>&nbsp;&nbsp;|&nbsp;&nbsp;</span>
        <a href="https://semaphore.appliedzkp.org/discord">
            üó£Ô∏è Next Steps
        </a>
    </h4>
</div>

| IEF is a platform designed to enable RetroPGF Round 3 nominees to evaluate a random set of peer nominees projects impact anonymously. Through this evaluation, they can attest to the correct self-evaluation of others and help improve the current information gap badgeholders that are not familiar with a specific category might have.
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |

Leveraging UniRep, IEF ensures that only projects who have submitted a self-reported impact evaluation, and are therefore familiar with the Impact Evaluation Framework, can evaluate peers **in an anonymous manner** using zero knowledge. 



## üì¶ Problem(s)

                                 Measuring the impact generated by public goods projects in web3 is hard. 
This obstacle was evident during Optimism's RetroPGF Round2, where measuring impact was a [challenge](https://optimism.mirror.xyz/7v1DehEY3dpRcYFhqWrVNc9Qj94H2L976LKlWH1FX-8) both to Nominees (who didn't know how to measure their impact for others to see) and for badgeholders (who didn't know how to assess the impact a project had). 

## Why is this a problem?
  An innability to measure the impact a public goods project creates ripple effects that harm the Ethereum Ecosystem ability to thrive in the future by:
  
  ### Underfunding Public Goods: 

Projects that are unable to measure and communicate the impact of the work they have done will leave money on the table that badgeholders would have been willing to commit given the right information. Taken to the extreme, if not enough resources are allocated to a project, the public good being provided by it may cease to exist. 

 ### Top-down incomplete evaluations: 
 
In the second round of RetroPGF, badgeholders were given limited guidance on how to assess the impact of the proposed projects. This presented a dual-edged problem. 

On one hand, the badgeholders, responsible for evaluating the projects, encountered difficulties when they had to assess projects in fields that were outside of their areas of expertise or familiarity. Without sufficient resources or context-specific knowledge, their ability to thoroughly evaluate the effectiveness and potential impact of these projects was impaired. 

On the other hand, and perhaps more critically, the nominees who proposed these projects faced top-down evaluations that might not have taken into account Key Performance Indicators (KPIs) significant to their on-the-ground operations. This issue stemmed from a potential disconnect between the evaluators' perspectives and the realities of hands-on fieldwork. 

There are specific indicators and factors that are vitally important and unique to ground-level work, which might not be visible, known, or may even be dismissed as irrelevant from the standpoint of someone who hasn't been involved in such in-situ operations. Consequently, these evaluations might have overlooked some crucial aspects of the projects, thereby affecting the comprehensiveness and accuracy of the assessments.

### Inability to scale:

During the RetroPGF process, the limited amount of information supplied to badgeholders posed a significant challenge. It necessitated an increased commitment of time as badgeholders needed to liaise with their counterparts to determine an effective approach for assessing the impact of projects. They were compelled to sift through the provided information, identify any gaps in data, and deliberate over which metrics should be the determining factors in the allocation of votes.

This process was time-consuming and could potentially become unmanageable as the number of projects involved in RetroPGF grows. The design and expectation of RetroPGF is to see an increase in participating projects. However, with the current system, it may result in an overwhelming workload for badgeholders. They may find it increasingly challenging to thoroughly review each project and thoughtfully distribute their votes due to time constraints.

As it stands, without more comprehensive guidelines and support, the expanding scope of RetroPGF might exceed the badgeholders' capacity to perform careful, conscientious evaluations, compromising the effectiveness and fairness of the entire process. There is an urgent need to streamline and enhance the evaluation framework to ensure its scalability and efficacy as the initiative grows.

## üí° Solution

IEF proposes a 3-step process to address the challenge in measuring the impact of public goods projects applying for RetroPGF. 
This process is only possible with the creation, and upkeep of an Impact Evaluation Framework that provides opt-in guidelines on a) how KPI's to measure impact are created and measured (at a technical level), b) offers a non-exhaustive set of KPI's that are commonly used by projects to evaluate their impact, and the logic behind those KPI's (these can be used as inspiration on how to create new KPI's), c) the importance of empowering operators to self-assess, d) guidelines to generate both quantitative and qualitative evaluations, e) the dangers of over-meassuring. 

Leveraging this Impact Evaluation Framework, I suggest the following process to evaluate impact: 


<table>
    <th>Stage</th>
    <th>Name</th>
    <th>Description</th>
    <tbody>
        <tr>
            <td>
                1
            </td>
            <td>
                Semaphore explorer for on-chain groups.
            </td>
            <td>    
                <a href="https://github.com/semaphore-protocol/explorer">
                    Github
                </a>|
                <a href="https://semaphore.appliedzkp.org/discord">
                    Discord
                </a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://discord.com/api/oauth2/authorize?client_id=1082429985496772628&permissions=1024&scope=bot">
                    Semaphore Discord Bot
                </a>
            </td>
            <td>
                A Discord bot for Semaphore.
            </td>
            <td>    
                <a href="https://github.com/semaphore-protocol/discord-bot">
                    Github
                </a>|
                <a href="https://semaphore.appliedzkp.org/discord">
                    Discord
                </a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://developer.unirep.io">
                    Unirep
                </a>
            </td>
            <td>
                Private and nonrepudiable reputation system based on ZKP.
            </td>
            <td>    
                <a href="https://github.com/Unirep">
                    Github
                </a>|
                <a href="https://discord.gg/VzMMDJmYc5">
                    Discord
                </a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://zk-proof-of-humanity.vercel.app">
                    ZK Proof of Humanity
                </a>
            </td>
            <td>
                A project to allows humans, registered in Proof of Humanity, to prove their humanity without doxing.
            </td>
            <td>    
                <a href="https://github.com/elmol/zk-proof-of-humanity">
                    Github
                </a>
            </td>
        </tr>
        <tr>
            <td>
                Plurality
            </td>
            <td>
                An Identity Lego Building Block for dapp creators that lets them identify their users without</br> using any third-party KYC provider or other middlemen, whilst preserving the privacy of users.
            </td>
            <td>    
                <a href="https://github.com/Web3-Plurality">
                    Github
                </a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://zerotherapy.vercel.app">
                    ZeroTherapy
                </a>
            </td>
            <td>
                AMA privacy application built with Semaphore.
            </td>
            <td>    
                <a href="https://github.com/Pushpit07/ZeroTherapy">
                    Github
                </a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://bq2.netlify.app/">
                    Block Qualified
                </a>
            </td>
            <td>
                On-chain and privacy preserving education platform built on Semaphore.
            </td>
            <td>    
                <a href="https://github.com/0xdeenz/bq2">
                    Github
                </a>
            </td>
        </tr>
    <tbody>
</table>

## üõ† Install

Clone this repository:

```bash
git clone https://github.com/semaphore-protocol/semaphore.git
```

And install the dependencies:

```bash
cd semaphore && yarn
```

## üìú Usage

Copy the `.env.example` file as `.env`:

```bash
cp .env.example .env
```

And add your environment variables.

### Code quality and formatting

Run [ESLint](https://eslint.org/) to analyze the code and catch bugs:

```bash
yarn lint
```

Run [Prettier](https://prettier.io/) to check formatting rules:

```bash
yarn prettier
```

Or to automatically format the code:

```bash
yarn prettier:write
```

### Conventional commits

Semaphore uses [conventional commits](https://www.conventionalcommits.org/en/v1.0.0/). A [command line utility](https://github.com/commitizen/cz-cli) to commit using the correct syntax can be used by running:

```bash
yarn commit
```

It will also automatically check that the modified files comply with ESLint and Prettier rules.

### Snark artifacts

Download the Semaphore snark artifacts needed to generate and verify proofs:

```bash
yarn download:snark-artifacts
```

### Testing

Run [Jest](https://jestjs.io/) to test the JS libraries:

```bash
yarn test:libraries
```

Run [Mocha](https://mochajs.org/) to test the contracts:

```bash
yarn test:contracts
```

Or test everything with:

```bash
yarn test
```

### Build libraries & compile contracts

Run [Rollup](https://www.rollupjs.org) to build all the packages:

```bash
yarn build:libraries
```

Compile the smart contracts with [Hardhat](https://hardhat.org/):

```bash
yarn compile:contracts
```

### Documentation (JS libraries)

Run [TypeDoc](https://typedoc.org/) to generate a documentation website for each package:

```bash
yarn docs
```

The output will be placed on the `docs` folder.
